{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \"\"\"Alexandru most  dangerous ensemble \"\"\"\n",
    "import os\n",
    " \n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "from sklearn.metrics import r2_score\n",
    "from __future__ import division\n",
    "import pandas as pd \n",
    "import  random as random\n",
    "import numpy as np\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import heapq\n",
    "from sklearn.linear_model import  LinearRegression,BayesianRidge\n",
    "from sklearn.ensemble import  RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import *\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import *\n",
    " \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import ml_metrics\n",
    "from ml_metrics import quadratic_weighted_kappa\n",
    "class BadErrorTreshold(Exception):\n",
    "    pass\n",
    " \n",
    "class EnsembleRegressors(object):\n",
    "    ''''\n",
    "    ensembleRegressor is a class of ensembles generated by a  fix number of  iterations.This class is abstract \n",
    "    meaning  it  is not possible  to create instances  of it.,,stochasticLearning''  has interface  role. '''\n",
    "    def __init__(self,regressors,sampling,iterations,test,X,y,k_fold):\n",
    "        ''''intialize ensemble with  near all  parameters- see that   some of them are  intialized  by other methods'''\n",
    "        self.sampling=sampling#dropout(cv) ratio-percentage\n",
    "        if (self.sampling<=0.0 or self.sampling>=1.0):\n",
    "            raise ValueError('Sampling  must be percent like value between[0,1) ex 0.75, you introduced :',self.sampling)\n",
    " \n",
    " \n",
    "        self.test=test#final test set\n",
    "        self.X=X#original train features\n",
    "        self.y=y#original train outcome\n",
    "        self.iterations=iterations#number of  iterations in the  stochastic ensemble\n",
    "        self.regressors=regressors#ensemble models  for  each iteration      \n",
    "        self.randomIndexes=[ [] for rounds in range(self.iterations)]#filled in with random dropout  by getStochasticDataSets()\n",
    "        self.error=[]#error for  each averaged iteration\n",
    " \n",
    " \n",
    "        self.stochasticPredictions=[ [] for  rounds in range(self.iterations)]#predictions on random drop outs\n",
    "        self.finalPredictions=[]\n",
    " \n",
    "        self.x_train=[]#his   next  4 rows are intialized  by getStochasticDataSets() according to random chunks\n",
    "        self.y_train=[]\n",
    "        self.x_test=[]\n",
    "        self.y_test=[]\n",
    " \n",
    "        self.new_x_ts=[]\n",
    "        self.new_x_tr=[]\n",
    "        self.new_test_final=[]\n",
    "        self.k_folds=k_fold\n",
    "        \n",
    "    def returnError(self):\n",
    "        '''returns : error for  each iteration-just like cross-validation'''\n",
    "        return self.error\n",
    "    \n",
    "    def returnRandomIndexes(self):\n",
    "        '''returns: random  indexes  for  each dropout'''\n",
    "        return self.randomIndexes\n",
    "    \n",
    "    def returnstochasticPredictions(self):\n",
    "        '''returns:predictions  on random dropous'''\n",
    "        return self.stochasticPredictions\n",
    "    \n",
    "    def getStochasticDataSets(self):\n",
    "        '''\n",
    "        For some  potentially  iteration creates a random  idx variable representing the index  for random  dropout.\n",
    "        Splits the train in  train/test(x_train,y_train,features and outcome for cross val train-x_test,y_test for cross_val test\n",
    "        .Updated this train-test  variables with corresponding  values.See that  the initial vales are empty in the __init__.\n",
    "        returns: idx(index of  dropout rows).\n",
    "        \n",
    "        '''\n",
    "        x_train, x_test, y_train, y_test = train_test_split(self.X, self.y, test_size=self.sampling)\n",
    "        self.x_train=x_train\n",
    "        self.x_test=x_test\n",
    "        self.y_train=y_train\n",
    "        self.y_test=y_test\n",
    "        #train_i, test_i = train_test_split(np.arange(self.X.shape[0]), train_size = self.sampling)\n",
    "        #self.x_train=self.X[train_i]\n",
    "        #self.y_train=self.y[train_i]\n",
    "        #self.x_test=self.X[test_i]\n",
    "        #self.y_test=self.y[test_i]\n",
    "        #idx=test_i\n",
    "        #return  idx\n",
    "    \n",
    "    def training(self,i):\n",
    "        ''''\n",
    "        For a  particular iteration ,,i''  calls getStochasticDataSets() method.In this was the randomIndexes feature is\n",
    "        fiiled with corresponding index dropouts at position ,,i''.Since train/test new data sets according to cross validation\n",
    "        are   filled  by getStochasticDataSets()  independet  of iteration number , this data sets will update for each new iter.\n",
    "        performmed in stochasticLearning().'''\n",
    "        self.getStochasticDataSets()\n",
    "        #blending- we have x_train,y_train,x_test,y_test   our stochastic  dropouts for diversity\n",
    "        #we are  going first  to make blend train,blend test from this dropoutsthen will see evaluation on the dropout\n",
    "        clfs=self.regressors\n",
    "        n_folds=self.k_folds\n",
    "        skf=list(StratifiedKFold(self.y_train,n_folds))\n",
    "        blend_tr=np.zeros((self.x_train.shape[0],len(clfs)))\n",
    "        blend_ts=np.zeros((self.x_test.shape[0],len(clfs)))#for loca al evaluation\n",
    "        blend_final_test=np.zeros((self.test.shape[0],len(clfs)))\n",
    " \n",
    "        for  j , clf in  enumerate(clfs):\n",
    "            print(clf)\n",
    "            blend_ts_j=np.zeros((self.x_test.shape[0],len(skf)))\n",
    "            blend_final_j=np.zeros((self.test.shape[0],len(skf)))\n",
    "            for i ,(tr,ts) in enumerate(skf):\n",
    "                print(\"fold\",i)\n",
    "                x_tr=self.x_train[tr]\n",
    "                y_tr=self.y_train[tr]\n",
    "                x_ts=self.x_train[ts]\n",
    "                y_ts=self.y_train[ts]\n",
    "                clf.fit(x_tr,y_tr)\n",
    "                y_sub=clf.predict_proba(x_ts)[:,1]\n",
    "                blend_tr[ts,j]=y_sub\n",
    "                blend_ts_j[:,i]=clf.predict_proba(self.x_test)[:,1]\n",
    "                blend_final_j[:,i]=clf.predict_proba(self.test)[:,1]\n",
    "            blend_ts[:,j]=blend_ts_j.mean(1)\n",
    "            blend_final_test[:,j]=blend_final_j.mean(1)\n",
    "        #blend on evaluation\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(blend_tr, self.y_train)\n",
    "        \n",
    "        pred_eval=  clf.predict_proba(blend_ts)[:,1]\n",
    "        self.error.append(log_loss(self.y_test,pred_eval))\n",
    "        #blend  on final test set:\n",
    "        final_sub=clf.predict_proba(blend_final_test)[:,1]\n",
    "        self.finalPredictions.append(final_sub)\n",
    "        \n",
    "        \n",
    " \n",
    "        return self\n",
    "    \n",
    "    def getFinalPrediction(self,errorTreshold):\n",
    "       raise NotImplementedError###averages models  according to best top prediction  trehsold  with different implementantions\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    def stochasticLearning(self):\n",
    "         raise NotImplementedError#Since EnsemebleRegressors class is abstract this will act  as an interface\n",
    "                                  #and will be implemented   by  this  EnsembleRegressors sublclasses  for averaging and\n",
    "                                  #weighted average\n",
    "    \n",
    "        \n",
    "class AveragingModels(EnsembleRegressors):\n",
    "    '''Inherits everything from EnsembleRegressors  class and implements stochastiLearning method  averaging models \n",
    "    for each iteration'''\n",
    " \n",
    "    def stochasticLearning(self):\n",
    "        \n",
    "        \n",
    "        for iter in range(self.iterations):\n",
    "            print('Stochastic Iteration number ',iter)\n",
    "            self.training(iter)\n",
    " \n",
    "    def getFinalPrediction(self,errorTreshold):\n",
    "        if (errorTreshold<=self.iterations and errorTreshold>0):\n",
    "            \n",
    "            topErrorIndex=heapq.nsmallest(errorTreshold, range(len(self.error)), self.error.__getitem__)\n",
    "            finalAvg=0\n",
    "            for topError in topErrorIndex:\n",
    "                finalAvg=finalAvg+self.finalPredictions[topError]\n",
    "            finalAvg=(finalAvg)/float(len(topErrorIndex))\n",
    "            return finalAvg\n",
    "        else:\n",
    "            raise BadErrorTreshold\n",
    "       \n",
    "       \n",
    "    \n",
    "                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read stuff\n",
    "import pandas  as pd\n",
    "import numpy as np\n",
    "train=pd.read_csv('anotherTrainThing.csv')\n",
    "test=pd.read_csv('anotherTestThing.csv')\n",
    "y=train['target']\n",
    "train=train.drop('target',1)\n",
    "train=train.drop('ID',1)\n",
    "ID=test['ID']\n",
    " \n",
    "\n",
    "test=test.drop('ID',1)\n",
    "from sklearn.metrics import log_loss\n",
    "trainvec=np.array(train)\n",
    "testvec=np.array(test)\n",
    "y=np.array(y)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114321, 132)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import  xgboost as xgb\n",
    "\"\"\"define classifiers\"\"\"\n",
    "clfs = [RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "            GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=7, n_estimators=100),\n",
    "            RandomForestClassifier(n_estimators=120, n_jobs=-1, criterion='gini'),\n",
    "            RandomForestClassifier(n_estimators=80, n_jobs=-1, criterion='entropy'),\n",
    "            ExtraTreesClassifier(n_estimators=120, n_jobs=-1, criterion='gini'),\n",
    "            RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "            RandomForestClassifier(n_estimators=150, n_jobs=-1, criterion='entropy'),\n",
    "            ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='gini'),\n",
    "            ExtraTreesClassifier(n_estimators=100, n_jobs=-1, criterion='entropy'),\n",
    "            GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=7, n_estimators=80),\n",
    "            ExtraTreesClassifier(n_estimators=70, n_jobs=-1, criterion='gini'),\n",
    "            GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=50),\n",
    "            RandomForestClassifier(n_estimators=170, n_jobs=-1, criterion='gini'),\n",
    "            GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=8, n_estimators=120),\n",
    "            RandomForestClassifier(n_estimators=180, n_jobs=-1, criterion='entropy'),\n",
    "            RandomForestClassifier(n_estimators=200, n_jobs=-1, criterion='entropy'),\n",
    "            ExtraTreesClassifier(n_estimators=120, n_jobs=-1, criterion='gini')\n",
    "            \n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Iteration number  0\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=10, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    }
   ],
   "source": [
    "\"\"\" run stuff with  0.1 dropout , 3 iterations,predict on testvec, train on trainvec and  y ,do 10\n",
    "stratified  sampling\"\"\"\n",
    "import  xgboost  as xgb\n",
    " \n",
    "o=AveragingModels(clfs,0.1,1,testvec,trainvec,y,10)\n",
    "o.stochasticLearning()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48349370356240173]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.error# please  look  at local error   before  submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see LB  on 1   iteration\n",
    "p=o.getFinalPrediction(1)\n",
    "p=p.reshape(p.shape[0])\n",
    "prediction=pd.DataFrame({\"ID\":ID,\"PredictedProb\":p})\n",
    "prediction.to_csv(\"attemp1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
